{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b9e91fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "import sklearn\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import warnings\n",
    "import scipy.stats as stats\n",
    "import urllib\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "import scipy.stats\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import skew\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e37d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "s = 117\n",
    "f= 2.8\n",
    "fff=f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87de56a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laser power</th>\n",
       "      <th>Scan speed</th>\n",
       "      <th>Line spacing</th>\n",
       "      <th>Layer thickness</th>\n",
       "      <th>STMPS-Width</th>\n",
       "      <th>STMPS-Depth</th>\n",
       "      <th>STMPS-Height</th>\n",
       "      <th>AMPS-Width</th>\n",
       "      <th>AMPS-Depth</th>\n",
       "      <th>AMPS-Height</th>\n",
       "      <th>Line spacing / H_max</th>\n",
       "      <th>Keyholing</th>\n",
       "      <th>Vapor depression zone</th>\n",
       "      <th>Relative density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.108333</td>\n",
       "      <td>82.940000</td>\n",
       "      <td>78.004333</td>\n",
       "      <td>211.424928</td>\n",
       "      <td>129.658</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.730037</td>\n",
       "      <td>0.613258</td>\n",
       "      <td>12.09494</td>\n",
       "      <td>97.211366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.108333</td>\n",
       "      <td>82.940000</td>\n",
       "      <td>78.004333</td>\n",
       "      <td>211.424928</td>\n",
       "      <td>129.658</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.672677</td>\n",
       "      <td>0.613258</td>\n",
       "      <td>12.09494</td>\n",
       "      <td>96.486870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.108333</td>\n",
       "      <td>82.940000</td>\n",
       "      <td>78.004333</td>\n",
       "      <td>211.424928</td>\n",
       "      <td>129.658</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.615317</td>\n",
       "      <td>0.613258</td>\n",
       "      <td>12.09494</td>\n",
       "      <td>98.278227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.108333</td>\n",
       "      <td>82.940000</td>\n",
       "      <td>78.004333</td>\n",
       "      <td>211.424928</td>\n",
       "      <td>129.658</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.557957</td>\n",
       "      <td>0.613258</td>\n",
       "      <td>12.09494</td>\n",
       "      <td>99.268814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.108333</td>\n",
       "      <td>82.940000</td>\n",
       "      <td>78.004333</td>\n",
       "      <td>211.424928</td>\n",
       "      <td>129.658</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.500597</td>\n",
       "      <td>0.613258</td>\n",
       "      <td>12.09494</td>\n",
       "      <td>96.606386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.108333</td>\n",
       "      <td>82.940000</td>\n",
       "      <td>78.004333</td>\n",
       "      <td>211.424928</td>\n",
       "      <td>129.658</td>\n",
       "      <td>15.50</td>\n",
       "      <td>0.443237</td>\n",
       "      <td>0.613258</td>\n",
       "      <td>12.09494</td>\n",
       "      <td>94.637494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>250</td>\n",
       "      <td>400</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.461667</td>\n",
       "      <td>184.457667</td>\n",
       "      <td>92.244667</td>\n",
       "      <td>233.345238</td>\n",
       "      <td>135.178</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.669424</td>\n",
       "      <td>0.579305</td>\n",
       "      <td>6.55738</td>\n",
       "      <td>98.801348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>250</td>\n",
       "      <td>400</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.461667</td>\n",
       "      <td>184.457667</td>\n",
       "      <td>92.244667</td>\n",
       "      <td>233.345238</td>\n",
       "      <td>135.178</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.768424</td>\n",
       "      <td>0.579305</td>\n",
       "      <td>6.55738</td>\n",
       "      <td>95.357015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>250</td>\n",
       "      <td>400</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.461667</td>\n",
       "      <td>184.457667</td>\n",
       "      <td>92.244667</td>\n",
       "      <td>233.345238</td>\n",
       "      <td>135.178</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.716567</td>\n",
       "      <td>0.579305</td>\n",
       "      <td>6.55738</td>\n",
       "      <td>77.263249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250</td>\n",
       "      <td>400</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.04</td>\n",
       "      <td>182.461667</td>\n",
       "      <td>184.457667</td>\n",
       "      <td>92.244667</td>\n",
       "      <td>233.345238</td>\n",
       "      <td>135.178</td>\n",
       "      <td>18.25</td>\n",
       "      <td>0.617567</td>\n",
       "      <td>0.579305</td>\n",
       "      <td>6.55738</td>\n",
       "      <td>98.072511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Laser power  Scan speed  Line spacing  Layer thickness  STMPS-Width  \\\n",
       "0          200         400         0.140             0.04   182.108333   \n",
       "1          200         400         0.129             0.04   182.108333   \n",
       "2          200         400         0.118             0.04   182.108333   \n",
       "3          200         400         0.107             0.04   182.108333   \n",
       "4          200         400         0.096             0.04   182.108333   \n",
       "5          200         400         0.085             0.04   182.108333   \n",
       "6          250         400         0.142             0.04   182.461667   \n",
       "7          250         400         0.163             0.04   182.461667   \n",
       "8          250         400         0.152             0.04   182.461667   \n",
       "9          250         400         0.131             0.04   182.461667   \n",
       "\n",
       "   STMPS-Depth  STMPS-Height  AMPS-Width  AMPS-Depth  AMPS-Height  \\\n",
       "0    82.940000     78.004333  211.424928     129.658        15.50   \n",
       "1    82.940000     78.004333  211.424928     129.658        15.50   \n",
       "2    82.940000     78.004333  211.424928     129.658        15.50   \n",
       "3    82.940000     78.004333  211.424928     129.658        15.50   \n",
       "4    82.940000     78.004333  211.424928     129.658        15.50   \n",
       "5    82.940000     78.004333  211.424928     129.658        15.50   \n",
       "6   184.457667     92.244667  233.345238     135.178        18.25   \n",
       "7   184.457667     92.244667  233.345238     135.178        18.25   \n",
       "8   184.457667     92.244667  233.345238     135.178        18.25   \n",
       "9   184.457667     92.244667  233.345238     135.178        18.25   \n",
       "\n",
       "   Line spacing / H_max  Keyholing  Vapor depression zone  Relative density  \n",
       "0              0.730037   0.613258               12.09494         97.211366  \n",
       "1              0.672677   0.613258               12.09494         96.486870  \n",
       "2              0.615317   0.613258               12.09494         98.278227  \n",
       "3              0.557957   0.613258               12.09494         99.268814  \n",
       "4              0.500597   0.613258               12.09494         96.606386  \n",
       "5              0.443237   0.613258               12.09494         94.637494  \n",
       "6              0.669424   0.579305                6.55738         98.801348  \n",
       "7              0.768424   0.579305                6.55738         95.357015  \n",
       "8              0.716567   0.579305                6.55738         77.263249  \n",
       "9              0.617567   0.579305                6.55738         98.072511  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_excel('./Printability_map_Data_python.xlsx', sheet_name='Densification')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c125445d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(627, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99faadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"STMPS-Width\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7571568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Laser power</th>\n",
       "      <th>Scan speed</th>\n",
       "      <th>Line spacing</th>\n",
       "      <th>Layer thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>627 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Laser power  Scan speed  Line spacing  Layer thickness\n",
       "0            200         400         0.140             0.04\n",
       "1            200         400         0.129             0.04\n",
       "2            200         400         0.118             0.04\n",
       "3            200         400         0.107             0.04\n",
       "4            200         400         0.096             0.04\n",
       "..           ...         ...           ...              ...\n",
       "622          500        1000         0.138             0.08\n",
       "623          500        1000         0.123             0.08\n",
       "624          500        1000         0.108             0.08\n",
       "625          500        1000         0.078             0.08\n",
       "626          500        1000         0.063             0.08\n",
       "\n",
       "[627 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data = df[['Laser power', 'Scan speed', 'Line spacing','Layer thickness']] \n",
    "y_data = df[[key]].copy();\n",
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62f6ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x_data, y_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "874f5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 4, activation = 'relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(units = 8, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(units = 1)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8279475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.05),loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5267add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "75/75 [==============================] - 0s 1ms/step - loss: 7558.2725 - val_loss: 1708.3833\n",
      "Epoch 2/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 2468.3542 - val_loss: 3378.8135\n",
      "Epoch 3/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 2375.4167 - val_loss: 3405.4741\n",
      "Epoch 4/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 2322.4368 - val_loss: 2129.2009\n",
      "Epoch 5/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 2056.5413 - val_loss: 1775.8147\n",
      "Epoch 6/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 2480.9846 - val_loss: 2194.0081\n",
      "Epoch 7/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 2209.2117 - val_loss: 2357.0955\n",
      "Epoch 8/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1882.7494 - val_loss: 1674.4576\n",
      "Epoch 9/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1947.6787 - val_loss: 1662.4957\n",
      "Epoch 10/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1960.5657 - val_loss: 6499.7295\n",
      "Epoch 11/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 2090.8499 - val_loss: 3846.8682\n",
      "Epoch 12/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 2129.4404 - val_loss: 1920.9283\n",
      "Epoch 13/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 2057.4285 - val_loss: 1504.2729\n",
      "Epoch 14/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 2173.3413 - val_loss: 2600.2427\n",
      "Epoch 15/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1815.3573 - val_loss: 2047.5150\n",
      "Epoch 16/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1843.6753 - val_loss: 2108.9155\n",
      "Epoch 17/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1729.4413 - val_loss: 1519.1259\n",
      "Epoch 18/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1630.7488 - val_loss: 1930.0000\n",
      "Epoch 19/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1856.9976 - val_loss: 1972.6189\n",
      "Epoch 20/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1739.4741 - val_loss: 1435.0184\n",
      "Epoch 21/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1732.2167 - val_loss: 1401.0697\n",
      "Epoch 22/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1575.1719 - val_loss: 1612.8442\n",
      "Epoch 23/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1592.7524 - val_loss: 1472.6340\n",
      "Epoch 24/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1391.4878 - val_loss: 1621.0087\n",
      "Epoch 25/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1485.5903 - val_loss: 1438.1323\n",
      "Epoch 26/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1780.7504 - val_loss: 1251.5437\n",
      "Epoch 27/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1387.1030 - val_loss: 1246.3158\n",
      "Epoch 28/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1351.8831 - val_loss: 1253.3483\n",
      "Epoch 29/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1296.6228 - val_loss: 1442.7579\n",
      "Epoch 30/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1165.5437 - val_loss: 1112.8416\n",
      "Epoch 31/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1127.9941 - val_loss: 1036.8751\n",
      "Epoch 32/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 994.6398 - val_loss: 1203.9242\n",
      "Epoch 33/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 926.0246 - val_loss: 1130.1152\n",
      "Epoch 34/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1152.8778 - val_loss: 1158.3749\n",
      "Epoch 35/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1175.3757 - val_loss: 1121.1720\n",
      "Epoch 36/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1152.3695 - val_loss: 1126.3595\n",
      "Epoch 37/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1147.6356 - val_loss: 1231.4401\n",
      "Epoch 38/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1158.0421 - val_loss: 1132.8148\n",
      "Epoch 39/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1170.5122 - val_loss: 1142.3602\n",
      "Epoch 40/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1153.9385 - val_loss: 1120.9624\n",
      "Epoch 41/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1170.7777 - val_loss: 1152.6080\n",
      "Epoch 42/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.2233 - val_loss: 1131.3983\n",
      "Epoch 43/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1142.2739 - val_loss: 1142.1097\n",
      "Epoch 44/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1160.8899 - val_loss: 1120.8116\n",
      "Epoch 45/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1158.8573 - val_loss: 1144.4143\n",
      "Epoch 46/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.1031 - val_loss: 1120.7938\n",
      "Epoch 47/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1163.7604 - val_loss: 1150.3384\n",
      "Epoch 48/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1151.6672 - val_loss: 1121.2035\n",
      "Epoch 49/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1158.5330 - val_loss: 1178.3348\n",
      "Epoch 50/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1153.4014 - val_loss: 1120.7743\n",
      "Epoch 51/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1168.7842 - val_loss: 1207.0278\n",
      "Epoch 52/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1157.5900 - val_loss: 1135.2705\n",
      "Epoch 53/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1166.6510 - val_loss: 1165.4109\n",
      "Epoch 54/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1165.2524 - val_loss: 1131.7599\n",
      "Epoch 55/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1168.1166 - val_loss: 1141.3374\n",
      "Epoch 56/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1152.8644 - val_loss: 1128.0745\n",
      "Epoch 57/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1149.0994 - val_loss: 1154.7012\n",
      "Epoch 58/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1156.4701 - val_loss: 1130.7412\n",
      "Epoch 59/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1165.6337 - val_loss: 1120.7723\n",
      "Epoch 60/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.4713 - val_loss: 1124.8330\n",
      "Epoch 61/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1145.2938 - val_loss: 1141.9634\n",
      "Epoch 62/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.4547 - val_loss: 1156.3962\n",
      "Epoch 63/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1173.3457 - val_loss: 1169.3013\n",
      "Epoch 64/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1136.9833 - val_loss: 1132.1062\n",
      "Epoch 65/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1186.1233 - val_loss: 1149.7126\n",
      "Epoch 66/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1160.4877 - val_loss: 1193.1466\n",
      "Epoch 67/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1169.7145 - val_loss: 1129.1024\n",
      "Epoch 68/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1151.7651 - val_loss: 1173.4449\n",
      "Epoch 69/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1161.7123 - val_loss: 1159.1558\n",
      "Epoch 70/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1177.5450 - val_loss: 1121.4373\n",
      "Epoch 71/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1178.1517 - val_loss: 1140.2291\n",
      "Epoch 72/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1164.8502 - val_loss: 1143.9518\n",
      "Epoch 73/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.7740 - val_loss: 1144.2139\n",
      "Epoch 74/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1170.1440 - val_loss: 1122.5905\n",
      "Epoch 75/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1163.9049 - val_loss: 1157.9432\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 622us/step - loss: 1161.7021 - val_loss: 1130.3584\n",
      "Epoch 77/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1160.1521 - val_loss: 1143.6403\n",
      "Epoch 78/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1185.3726 - val_loss: 1136.8328\n",
      "Epoch 79/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1185.5341 - val_loss: 1128.4698\n",
      "Epoch 80/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1165.1796 - val_loss: 1156.0573\n",
      "Epoch 81/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1159.9119 - val_loss: 1195.6772\n",
      "Epoch 82/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1175.8452 - val_loss: 1154.4340\n",
      "Epoch 83/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.8497 - val_loss: 1153.0043\n",
      "Epoch 84/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1161.5367 - val_loss: 1145.8240\n",
      "Epoch 85/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1163.6331 - val_loss: 1304.0465\n",
      "Epoch 86/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1195.6750 - val_loss: 1120.7168\n",
      "Epoch 87/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1154.5107 - val_loss: 1228.6007\n",
      "Epoch 88/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1166.8176 - val_loss: 1122.1300\n",
      "Epoch 89/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1171.1005 - val_loss: 1135.6063\n",
      "Epoch 90/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1156.8041 - val_loss: 1222.1198\n",
      "Epoch 91/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1190.6669 - val_loss: 1139.0496\n",
      "Epoch 92/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1162.0249 - val_loss: 1142.5304\n",
      "Epoch 93/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1164.9337 - val_loss: 1144.4938\n",
      "Epoch 94/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1159.1760 - val_loss: 1122.1150\n",
      "Epoch 95/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1166.7615 - val_loss: 1120.8583\n",
      "Epoch 96/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1170.4741 - val_loss: 1123.9718\n",
      "Epoch 97/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.0194 - val_loss: 1187.4268\n",
      "Epoch 98/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1170.8798 - val_loss: 1276.5222\n",
      "Epoch 99/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1208.7616 - val_loss: 1129.0697\n",
      "Epoch 100/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.9474 - val_loss: 1126.4893\n",
      "Epoch 101/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1157.6740 - val_loss: 1194.3257\n",
      "Epoch 102/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1161.3853 - val_loss: 1129.4832\n",
      "Epoch 103/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1166.0129 - val_loss: 1174.9691\n",
      "Epoch 104/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1181.0439 - val_loss: 1136.8184\n",
      "Epoch 105/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.0613 - val_loss: 1130.8210\n",
      "Epoch 106/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1167.2690 - val_loss: 1131.4248\n",
      "Epoch 107/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1151.8623 - val_loss: 1183.0415\n",
      "Epoch 108/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1195.4734 - val_loss: 1178.2563\n",
      "Epoch 109/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1177.9756 - val_loss: 1120.8965\n",
      "Epoch 110/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1167.0874 - val_loss: 1130.1517\n",
      "Epoch 111/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1185.8311 - val_loss: 1203.3009\n",
      "Epoch 112/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.5287 - val_loss: 1211.5862\n",
      "Epoch 113/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1175.7207 - val_loss: 1140.8932\n",
      "Epoch 114/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1169.5073 - val_loss: 1178.2524\n",
      "Epoch 115/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1163.4459 - val_loss: 1153.3032\n",
      "Epoch 116/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1166.0496 - val_loss: 1154.2958\n",
      "Epoch 117/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1169.0476 - val_loss: 1123.2358\n",
      "Epoch 118/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1173.1578 - val_loss: 1133.8898\n",
      "Epoch 119/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1165.1165 - val_loss: 1205.5437\n",
      "Epoch 120/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.3085 - val_loss: 1141.5691\n",
      "Epoch 121/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1163.0509 - val_loss: 1147.4596\n",
      "Epoch 122/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1180.0579 - val_loss: 1429.5000\n",
      "Epoch 123/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1162.0403 - val_loss: 1123.3223\n",
      "Epoch 124/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1176.1034 - val_loss: 1136.5222\n",
      "Epoch 125/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1176.4807 - val_loss: 1162.7206\n",
      "Epoch 126/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1176.2395 - val_loss: 1141.5760\n",
      "Epoch 127/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.9618 - val_loss: 1134.0812\n",
      "Epoch 128/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1173.3928 - val_loss: 1135.4996\n",
      "Epoch 129/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1164.7386 - val_loss: 1146.1558\n",
      "Epoch 130/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1159.2463 - val_loss: 1120.6921\n",
      "Epoch 131/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1157.7909 - val_loss: 1135.8383\n",
      "Epoch 132/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1170.1726 - val_loss: 1197.3855\n",
      "Epoch 133/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1164.9189 - val_loss: 1157.8953\n",
      "Epoch 134/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1145.8580 - val_loss: 1123.1810\n",
      "Epoch 135/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1159.5017 - val_loss: 1125.7246\n",
      "Epoch 136/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1155.1320 - val_loss: 1132.7682\n",
      "Epoch 137/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1151.5275 - val_loss: 1163.7343\n",
      "Epoch 138/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1170.8905 - val_loss: 1139.8821\n",
      "Epoch 139/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1153.0504 - val_loss: 1122.1155\n",
      "Epoch 140/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1178.6899 - val_loss: 1197.8832\n",
      "Epoch 141/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1178.2599 - val_loss: 1127.1064\n",
      "Epoch 142/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1158.8231 - val_loss: 1129.4742\n",
      "Epoch 143/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1148.3364 - val_loss: 1130.1189\n",
      "Epoch 144/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1172.5626 - val_loss: 1126.3760\n",
      "Epoch 145/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1185.1013 - val_loss: 1258.6273\n",
      "Epoch 146/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1177.1211 - val_loss: 1131.3716\n",
      "Epoch 147/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1182.4331 - val_loss: 1120.6821\n",
      "Epoch 148/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1169.3057 - val_loss: 1129.5369\n",
      "Epoch 149/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1152.6036 - val_loss: 1215.9008\n",
      "Epoch 150/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1200.8502 - val_loss: 1128.6249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1180.0482 - val_loss: 1126.5287\n",
      "Epoch 152/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1163.0438 - val_loss: 1267.2931\n",
      "Epoch 153/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1178.1923 - val_loss: 1179.6575\n",
      "Epoch 154/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1160.2349 - val_loss: 1139.2565\n",
      "Epoch 155/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1164.3862 - val_loss: 1121.4646\n",
      "Epoch 156/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1159.1475 - val_loss: 1121.6245\n",
      "Epoch 157/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1169.6071 - val_loss: 1148.4702\n",
      "Epoch 158/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1170.3951 - val_loss: 1120.9440\n",
      "Epoch 159/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.6752 - val_loss: 1357.3213\n",
      "Epoch 160/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1170.0798 - val_loss: 1137.3640\n",
      "Epoch 161/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1155.8329 - val_loss: 1182.6101\n",
      "Epoch 162/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1169.7511 - val_loss: 1121.4543\n",
      "Epoch 163/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1159.9886 - val_loss: 1120.6818\n",
      "Epoch 164/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1162.9471 - val_loss: 1124.5854\n",
      "Epoch 165/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1164.3124 - val_loss: 1207.9912\n",
      "Epoch 166/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1183.9904 - val_loss: 1156.1686\n",
      "Epoch 167/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1154.6409 - val_loss: 1131.6630\n",
      "Epoch 168/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1161.9812 - val_loss: 1166.3622\n",
      "Epoch 169/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1158.3262 - val_loss: 1127.4808\n",
      "Epoch 170/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1182.6897 - val_loss: 1120.8702\n",
      "Epoch 171/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1160.5271 - val_loss: 1123.0573\n",
      "Epoch 172/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1147.9922 - val_loss: 1258.7750\n",
      "Epoch 173/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1191.4780 - val_loss: 1131.4054\n",
      "Epoch 174/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1165.5994 - val_loss: 1121.5817\n",
      "Epoch 175/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1178.8333 - val_loss: 1138.1732\n",
      "Epoch 176/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1164.6036 - val_loss: 1132.8535\n",
      "Epoch 177/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1214.0815 - val_loss: 1126.3608\n",
      "Epoch 178/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1167.5682 - val_loss: 1215.1345\n",
      "Epoch 179/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1172.5319 - val_loss: 1126.1194\n",
      "Epoch 180/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1171.1702 - val_loss: 1124.6708\n",
      "Epoch 181/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.2582 - val_loss: 1293.5978\n",
      "Epoch 182/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1169.9226 - val_loss: 1138.5487\n",
      "Epoch 183/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1205.8848 - val_loss: 1164.1978\n",
      "Epoch 184/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1181.9122 - val_loss: 1135.3021\n",
      "Epoch 185/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1166.4912 - val_loss: 1147.6565\n",
      "Epoch 186/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1166.1610 - val_loss: 1136.9266\n",
      "Epoch 187/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1169.8752 - val_loss: 1137.2671\n",
      "Epoch 188/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1172.8478 - val_loss: 1163.9531\n",
      "Epoch 189/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1144.4705 - val_loss: 1182.1266\n",
      "Epoch 190/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1162.4802 - val_loss: 1181.4342\n",
      "Epoch 191/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1167.0931 - val_loss: 1161.0604\n",
      "Epoch 192/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1173.9034 - val_loss: 1121.3445\n",
      "Epoch 193/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1168.4548 - val_loss: 1226.9683\n",
      "Epoch 194/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1160.2678 - val_loss: 1140.7520\n",
      "Epoch 195/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1166.0681 - val_loss: 1123.0408\n",
      "Epoch 196/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1152.7324 - val_loss: 1122.0215\n",
      "Epoch 197/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1162.6260 - val_loss: 1223.8394\n",
      "Epoch 198/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.6348 - val_loss: 1272.0630\n",
      "Epoch 199/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1158.4357 - val_loss: 1121.5663\n",
      "Epoch 200/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1202.1310 - val_loss: 1251.4714\n",
      "Epoch 201/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1161.1560 - val_loss: 1176.9238\n",
      "Epoch 202/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1151.3293 - val_loss: 1183.1053\n",
      "Epoch 203/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1176.0873 - val_loss: 1141.5192\n",
      "Epoch 204/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1178.0304 - val_loss: 1130.7194\n",
      "Epoch 205/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.8190 - val_loss: 1121.7775\n",
      "Epoch 206/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1185.0040 - val_loss: 1190.6943\n",
      "Epoch 207/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.0886 - val_loss: 1126.2893\n",
      "Epoch 208/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.4591 - val_loss: 1128.1223\n",
      "Epoch 209/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1162.9315 - val_loss: 1137.2518\n",
      "Epoch 210/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1153.7228 - val_loss: 1154.0509\n",
      "Epoch 211/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1167.9884 - val_loss: 1133.4012\n",
      "Epoch 212/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.2863 - val_loss: 1121.3025\n",
      "Epoch 213/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1173.0112 - val_loss: 1123.3916\n",
      "Epoch 214/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.9860 - val_loss: 1127.0131\n",
      "Epoch 215/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1165.9248 - val_loss: 1152.6062\n",
      "Epoch 216/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1163.8048 - val_loss: 1148.2096\n",
      "Epoch 217/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1155.4722 - val_loss: 1142.8279\n",
      "Epoch 218/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1169.0640 - val_loss: 1205.7811\n",
      "Epoch 219/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1170.3051 - val_loss: 1121.3331\n",
      "Epoch 220/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1164.6809 - val_loss: 1124.2155\n",
      "Epoch 221/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1176.9220 - val_loss: 1174.0382\n",
      "Epoch 222/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1153.2075 - val_loss: 1125.4937\n",
      "Epoch 223/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.1793 - val_loss: 1130.1984\n",
      "Epoch 224/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1177.7472 - val_loss: 1288.2649\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 622us/step - loss: 1164.1041 - val_loss: 1204.7035\n",
      "Epoch 226/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1166.8401 - val_loss: 1120.7092\n",
      "Epoch 227/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.9669 - val_loss: 1163.8315\n",
      "Epoch 228/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1159.3381 - val_loss: 1145.7195\n",
      "Epoch 229/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.7061 - val_loss: 1125.9060\n",
      "Epoch 230/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.0836 - val_loss: 1121.5695\n",
      "Epoch 231/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1193.8635 - val_loss: 1191.3738\n",
      "Epoch 232/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1162.3806 - val_loss: 1156.1698\n",
      "Epoch 233/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.7831 - val_loss: 1124.8641\n",
      "Epoch 234/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1163.8125 - val_loss: 1240.2882\n",
      "Epoch 235/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1184.7067 - val_loss: 1137.4772\n",
      "Epoch 236/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.7076 - val_loss: 1120.6807\n",
      "Epoch 237/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1152.3369 - val_loss: 1121.2159\n",
      "Epoch 238/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1170.0804 - val_loss: 1156.4717\n",
      "Epoch 239/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1170.6587 - val_loss: 1153.7584\n",
      "Epoch 240/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.4575 - val_loss: 1121.9176\n",
      "Epoch 241/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1171.0917 - val_loss: 1141.4684\n",
      "Epoch 242/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1173.2510 - val_loss: 1133.6023\n",
      "Epoch 243/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1167.5847 - val_loss: 1121.3074\n",
      "Epoch 244/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1180.2339 - val_loss: 1152.7054\n",
      "Epoch 245/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1165.5503 - val_loss: 1121.7794\n",
      "Epoch 246/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.5142 - val_loss: 1134.2625\n",
      "Epoch 247/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1163.3276 - val_loss: 1167.5845\n",
      "Epoch 248/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.2124 - val_loss: 1178.0703\n",
      "Epoch 249/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.1359 - val_loss: 1120.6984\n",
      "Epoch 250/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1157.1235 - val_loss: 1121.8617\n",
      "Epoch 251/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1169.1036 - val_loss: 1177.2083\n",
      "Epoch 252/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.0613 - val_loss: 1187.7764\n",
      "Epoch 253/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1228.3767 - val_loss: 1204.9237\n",
      "Epoch 254/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1165.6188 - val_loss: 1120.8763\n",
      "Epoch 255/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.4133 - val_loss: 1124.5314\n",
      "Epoch 256/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1192.7054 - val_loss: 1123.3038\n",
      "Epoch 257/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1159.4224 - val_loss: 1135.1487\n",
      "Epoch 258/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1172.7719 - val_loss: 1120.7800\n",
      "Epoch 259/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1158.6229 - val_loss: 1120.9183\n",
      "Epoch 260/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1145.1553 - val_loss: 1123.3485\n",
      "Epoch 261/1000\n",
      "75/75 [==============================] - 0s 770us/step - loss: 1160.5245 - val_loss: 1136.9922\n",
      "Epoch 262/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1163.3889 - val_loss: 1277.2308\n",
      "Epoch 263/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1166.5907 - val_loss: 1149.2271\n",
      "Epoch 264/1000\n",
      "75/75 [==============================] - 0s 770us/step - loss: 1162.0292 - val_loss: 1124.2168\n",
      "Epoch 265/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1158.9020 - val_loss: 1125.5400\n",
      "Epoch 266/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1158.8820 - val_loss: 1159.0591\n",
      "Epoch 267/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1168.7190 - val_loss: 1121.5076\n",
      "Epoch 268/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1147.1497 - val_loss: 1135.7745\n",
      "Epoch 269/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1162.5894 - val_loss: 1186.0605\n",
      "Epoch 270/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1157.6658 - val_loss: 1152.2606\n",
      "Epoch 271/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1166.2429 - val_loss: 1122.1937\n",
      "Epoch 272/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1162.0288 - val_loss: 1142.0952\n",
      "Epoch 273/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1175.9122 - val_loss: 1131.1060\n",
      "Epoch 274/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1177.3402 - val_loss: 1133.2615\n",
      "Epoch 275/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1153.2113 - val_loss: 1165.1855\n",
      "Epoch 276/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1157.5463 - val_loss: 1194.0964\n",
      "Epoch 277/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.5280 - val_loss: 1150.5803\n",
      "Epoch 278/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1161.1940 - val_loss: 1126.2994\n",
      "Epoch 279/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1166.2550 - val_loss: 1121.9020\n",
      "Epoch 280/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1173.8232 - val_loss: 1146.5139\n",
      "Epoch 281/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1160.1584 - val_loss: 1158.5757\n",
      "Epoch 282/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1154.0236 - val_loss: 1171.0063\n",
      "Epoch 283/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.2333 - val_loss: 1123.8202\n",
      "Epoch 284/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1164.9045 - val_loss: 1123.6013\n",
      "Epoch 285/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1155.0719 - val_loss: 1177.3132\n",
      "Epoch 286/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1162.9164 - val_loss: 1214.9625\n",
      "Epoch 287/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1158.9121 - val_loss: 1137.0173\n",
      "Epoch 288/1000\n",
      "75/75 [==============================] - 0s 595us/step - loss: 1173.0040 - val_loss: 1140.1699\n",
      "Epoch 289/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1158.3455 - val_loss: 1195.1339\n",
      "Epoch 290/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1153.9645 - val_loss: 1132.0862\n",
      "Epoch 291/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1151.8776 - val_loss: 1155.1205\n",
      "Epoch 292/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.5166 - val_loss: 1129.9545\n",
      "Epoch 293/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1164.7389 - val_loss: 1190.3159\n",
      "Epoch 294/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1164.4855 - val_loss: 1123.8844\n",
      "Epoch 295/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.0499 - val_loss: 1165.2719\n",
      "Epoch 296/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1168.6433 - val_loss: 1186.2462\n",
      "Epoch 297/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1152.8641 - val_loss: 1253.1136\n",
      "Epoch 298/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1162.0841 - val_loss: 1144.3351\n",
      "Epoch 299/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 635us/step - loss: 1177.6918 - val_loss: 1235.1403\n",
      "Epoch 300/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1160.9979 - val_loss: 1135.5106\n",
      "Epoch 301/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1172.7939 - val_loss: 1132.2893\n",
      "Epoch 302/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.3158 - val_loss: 1127.6465\n",
      "Epoch 303/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1155.8645 - val_loss: 1124.1669\n",
      "Epoch 304/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1167.0469 - val_loss: 1162.0416\n",
      "Epoch 305/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1145.5696 - val_loss: 1147.4508\n",
      "Epoch 306/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1169.2540 - val_loss: 1180.9877\n",
      "Epoch 307/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1171.0137 - val_loss: 1177.7008\n",
      "Epoch 308/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1160.9746 - val_loss: 1139.0737\n",
      "Epoch 309/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1153.1444 - val_loss: 1203.2928\n",
      "Epoch 310/1000\n",
      "75/75 [==============================] - 0s 595us/step - loss: 1163.3158 - val_loss: 1147.0830\n",
      "Epoch 311/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1173.5779 - val_loss: 1237.5344\n",
      "Epoch 312/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1159.1632 - val_loss: 1120.8480\n",
      "Epoch 313/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1149.7715 - val_loss: 1120.7300\n",
      "Epoch 314/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1158.1388 - val_loss: 1130.9498\n",
      "Epoch 315/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.6776 - val_loss: 1133.5887\n",
      "Epoch 316/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1161.7552 - val_loss: 1194.7471\n",
      "Epoch 317/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1137.8356 - val_loss: 1136.1316\n",
      "Epoch 318/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1190.9272 - val_loss: 1142.1295\n",
      "Epoch 319/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.7512 - val_loss: 1164.7289\n",
      "Epoch 320/1000\n",
      "75/75 [==============================] - 0s 595us/step - loss: 1149.1328 - val_loss: 1120.8638\n",
      "Epoch 321/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1185.7816 - val_loss: 1121.1987\n",
      "Epoch 322/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1165.5278 - val_loss: 1122.2423\n",
      "Epoch 323/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1166.7347 - val_loss: 1127.3757\n",
      "Epoch 324/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1185.2877 - val_loss: 1129.7637\n",
      "Epoch 325/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1168.3824 - val_loss: 1213.2036\n",
      "Epoch 326/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1162.9132 - val_loss: 1120.6919\n",
      "Epoch 327/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.4612 - val_loss: 1195.5079\n",
      "Epoch 328/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1158.6030 - val_loss: 1125.7155\n",
      "Epoch 329/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1133.6223 - val_loss: 1527.5399\n",
      "Epoch 330/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1189.0905 - val_loss: 1123.6333\n",
      "Epoch 331/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.6801 - val_loss: 1179.4109\n",
      "Epoch 332/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.1917 - val_loss: 1136.6611\n",
      "Epoch 333/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1148.6885 - val_loss: 1145.9307\n",
      "Epoch 334/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1185.6060 - val_loss: 1132.6519\n",
      "Epoch 335/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.8208 - val_loss: 1211.0509\n",
      "Epoch 336/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.5588 - val_loss: 1121.2625\n",
      "Epoch 337/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1184.2390 - val_loss: 1236.3495\n",
      "Epoch 338/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.6349 - val_loss: 1190.8734\n",
      "Epoch 339/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1177.7927 - val_loss: 1125.0773\n",
      "Epoch 340/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.2224 - val_loss: 1220.4980\n",
      "Epoch 341/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1165.7850 - val_loss: 1208.2250\n",
      "Epoch 342/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1152.1956 - val_loss: 1242.8589\n",
      "Epoch 343/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1184.7671 - val_loss: 1149.3256\n",
      "Epoch 344/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1178.8243 - val_loss: 1133.6741\n",
      "Epoch 345/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1142.1885 - val_loss: 1129.3967\n",
      "Epoch 346/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1170.7297 - val_loss: 1133.0691\n",
      "Epoch 347/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1153.9841 - val_loss: 1184.7213\n",
      "Epoch 348/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.0035 - val_loss: 1270.1060\n",
      "Epoch 349/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1167.1222 - val_loss: 1121.8234\n",
      "Epoch 350/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1166.4255 - val_loss: 1120.8958\n",
      "Epoch 351/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1159.3990 - val_loss: 1235.5073\n",
      "Epoch 352/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1154.9050 - val_loss: 1156.4976\n",
      "Epoch 353/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1154.8590 - val_loss: 1130.1769\n",
      "Epoch 354/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.3656 - val_loss: 1166.3245\n",
      "Epoch 355/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1160.9542 - val_loss: 1170.8768\n",
      "Epoch 356/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.8247 - val_loss: 1149.4307\n",
      "Epoch 357/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.0831 - val_loss: 1147.5513\n",
      "Epoch 358/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.6858 - val_loss: 1134.2765\n",
      "Epoch 359/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1156.6892 - val_loss: 1132.3307\n",
      "Epoch 360/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.2266 - val_loss: 1124.0942\n",
      "Epoch 361/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1140.3500 - val_loss: 1125.8444\n",
      "Epoch 362/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1162.6399 - val_loss: 1165.9673\n",
      "Epoch 363/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.4132 - val_loss: 1138.2235\n",
      "Epoch 364/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1161.2677 - val_loss: 1167.2357\n",
      "Epoch 365/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1158.8636 - val_loss: 1125.9814\n",
      "Epoch 366/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1159.3879 - val_loss: 1121.6571\n",
      "Epoch 367/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1163.8990 - val_loss: 1167.8606\n",
      "Epoch 368/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1188.8804 - val_loss: 1146.2601\n",
      "Epoch 369/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.7126 - val_loss: 1120.7529\n",
      "Epoch 370/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1153.2520 - val_loss: 1121.6014\n",
      "Epoch 371/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1172.6636 - val_loss: 1163.8787\n",
      "Epoch 372/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1161.9473 - val_loss: 1124.3923\n",
      "Epoch 373/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 689us/step - loss: 1160.0553 - val_loss: 1125.7660\n",
      "Epoch 374/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1156.3901 - val_loss: 1144.4641\n",
      "Epoch 375/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1172.4851 - val_loss: 1144.0824\n",
      "Epoch 376/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1168.5781 - val_loss: 1139.4849\n",
      "Epoch 377/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1165.1466 - val_loss: 1120.9915\n",
      "Epoch 378/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1166.4374 - val_loss: 1157.3036\n",
      "Epoch 379/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1160.9476 - val_loss: 1175.2960\n",
      "Epoch 380/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.4053 - val_loss: 1185.6967\n",
      "Epoch 381/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.5253 - val_loss: 1124.0339\n",
      "Epoch 382/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1162.7449 - val_loss: 1164.9281\n",
      "Epoch 383/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.9873 - val_loss: 1175.7172\n",
      "Epoch 384/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1146.3275 - val_loss: 1158.8739\n",
      "Epoch 385/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1173.6552 - val_loss: 1121.9380\n",
      "Epoch 386/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1174.0200 - val_loss: 1129.3821\n",
      "Epoch 387/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1159.4009 - val_loss: 1243.1368\n",
      "Epoch 388/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1153.7411 - val_loss: 1120.6796\n",
      "Epoch 389/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1155.9247 - val_loss: 1131.9010\n",
      "Epoch 390/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1158.6702 - val_loss: 1124.2916\n",
      "Epoch 391/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1173.1887 - val_loss: 1151.8860\n",
      "Epoch 392/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1157.3651 - val_loss: 1122.8694\n",
      "Epoch 393/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1153.8525 - val_loss: 1126.0804\n",
      "Epoch 394/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1158.1113 - val_loss: 1130.6410\n",
      "Epoch 395/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1148.8401 - val_loss: 1136.3361\n",
      "Epoch 396/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1152.3462 - val_loss: 1126.0667\n",
      "Epoch 397/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1154.9937 - val_loss: 1124.2800\n",
      "Epoch 398/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1163.9471 - val_loss: 1147.9741\n",
      "Epoch 399/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1158.8511 - val_loss: 1123.0205\n",
      "Epoch 400/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1184.2677 - val_loss: 1120.8522\n",
      "Epoch 401/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.8420 - val_loss: 1172.1442\n",
      "Epoch 402/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1144.0723 - val_loss: 1121.0597\n",
      "Epoch 403/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1181.1343 - val_loss: 1153.8516\n",
      "Epoch 404/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1160.2474 - val_loss: 1157.5485\n",
      "Epoch 405/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1155.0857 - val_loss: 1141.3538\n",
      "Epoch 406/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.7546 - val_loss: 1121.3291\n",
      "Epoch 407/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.6890 - val_loss: 1155.5355\n",
      "Epoch 408/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.1204 - val_loss: 1120.9496\n",
      "Epoch 409/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1168.1587 - val_loss: 1134.8154\n",
      "Epoch 410/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1161.1688 - val_loss: 1152.9243\n",
      "Epoch 411/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1169.0593 - val_loss: 1130.1462\n",
      "Epoch 412/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1148.6587 - val_loss: 1146.5612\n",
      "Epoch 413/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.7776 - val_loss: 1134.9869\n",
      "Epoch 414/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1167.0952 - val_loss: 1130.8656\n",
      "Epoch 415/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1163.3140 - val_loss: 1126.8035\n",
      "Epoch 416/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1154.2250 - val_loss: 1122.5353\n",
      "Epoch 417/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1152.5140 - val_loss: 1120.8447\n",
      "Epoch 418/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.4595 - val_loss: 1126.7032\n",
      "Epoch 419/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1154.2036 - val_loss: 1153.8522\n",
      "Epoch 420/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1141.0991 - val_loss: 1128.3081\n",
      "Epoch 421/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1174.6553 - val_loss: 1124.3551\n",
      "Epoch 422/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.3654 - val_loss: 1123.0782\n",
      "Epoch 423/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1174.9353 - val_loss: 1149.9723\n",
      "Epoch 424/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1168.4056 - val_loss: 1188.3213\n",
      "Epoch 425/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.6133 - val_loss: 1189.9856\n",
      "Epoch 426/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.6979 - val_loss: 1126.1805\n",
      "Epoch 427/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.6000 - val_loss: 1146.7543\n",
      "Epoch 428/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.5939 - val_loss: 1124.3932\n",
      "Epoch 429/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.5935 - val_loss: 1142.7089\n",
      "Epoch 430/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1150.2776 - val_loss: 1125.0179\n",
      "Epoch 431/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1144.2798 - val_loss: 1215.5807\n",
      "Epoch 432/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1167.3445 - val_loss: 1128.8032\n",
      "Epoch 433/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1144.9330 - val_loss: 1256.7974\n",
      "Epoch 434/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1154.2646 - val_loss: 1141.3468\n",
      "Epoch 435/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1157.3032 - val_loss: 1121.4983\n",
      "Epoch 436/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1164.4954 - val_loss: 1132.3232\n",
      "Epoch 437/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1164.2336 - val_loss: 1177.2582\n",
      "Epoch 438/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.2805 - val_loss: 1121.0222\n",
      "Epoch 439/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1144.6666 - val_loss: 1136.4095\n",
      "Epoch 440/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.3114 - val_loss: 1188.2423\n",
      "Epoch 441/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1157.6958 - val_loss: 1141.0167\n",
      "Epoch 442/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1156.3625 - val_loss: 1142.7587\n",
      "Epoch 443/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1160.7430 - val_loss: 1146.8556\n",
      "Epoch 444/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1147.0970 - val_loss: 1125.8339\n",
      "Epoch 445/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.4053 - val_loss: 1124.8153\n",
      "Epoch 446/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1147.0869 - val_loss: 1120.7732\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 622us/step - loss: 1172.7982 - val_loss: 1123.0698\n",
      "Epoch 448/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.9515 - val_loss: 1124.1362\n",
      "Epoch 449/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1155.9203 - val_loss: 1129.9972\n",
      "Epoch 450/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1184.9525 - val_loss: 1144.9213\n",
      "Epoch 451/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1147.2140 - val_loss: 1203.7809\n",
      "Epoch 452/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.8236 - val_loss: 1194.2225\n",
      "Epoch 453/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1165.3169 - val_loss: 1146.2443\n",
      "Epoch 454/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.1099 - val_loss: 1120.9039\n",
      "Epoch 455/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1160.9766 - val_loss: 1130.5471\n",
      "Epoch 456/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.5315 - val_loss: 1126.2615\n",
      "Epoch 457/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1164.7323 - val_loss: 1137.3156\n",
      "Epoch 458/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1152.7242 - val_loss: 1127.8389\n",
      "Epoch 459/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1163.3927 - val_loss: 1121.7712\n",
      "Epoch 460/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1154.0013 - val_loss: 1235.8291\n",
      "Epoch 461/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1156.4138 - val_loss: 1217.6887\n",
      "Epoch 462/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1170.8284 - val_loss: 1145.0563\n",
      "Epoch 463/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1164.0435 - val_loss: 1247.1096\n",
      "Epoch 464/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1163.0945 - val_loss: 1126.7635\n",
      "Epoch 465/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1169.5486 - val_loss: 1129.1816\n",
      "Epoch 466/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.5878 - val_loss: 1122.2659\n",
      "Epoch 467/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1164.3055 - val_loss: 1141.3639\n",
      "Epoch 468/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1164.4723 - val_loss: 1186.1666\n",
      "Epoch 469/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1165.3370 - val_loss: 1126.3607\n",
      "Epoch 470/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.5837 - val_loss: 1200.8505\n",
      "Epoch 471/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1152.2955 - val_loss: 1162.5554\n",
      "Epoch 472/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1145.3683 - val_loss: 1120.6987\n",
      "Epoch 473/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1175.1503 - val_loss: 1145.4369\n",
      "Epoch 474/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1179.2220 - val_loss: 1147.3960\n",
      "Epoch 475/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1145.4825 - val_loss: 1175.5925\n",
      "Epoch 476/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.5792 - val_loss: 1153.4967\n",
      "Epoch 477/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1157.0754 - val_loss: 1193.0952\n",
      "Epoch 478/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.5363 - val_loss: 1180.0703\n",
      "Epoch 479/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1153.1758 - val_loss: 1120.9271\n",
      "Epoch 480/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1148.6748 - val_loss: 1131.1865\n",
      "Epoch 481/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.8528 - val_loss: 1166.5334\n",
      "Epoch 482/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1153.2643 - val_loss: 1131.5804\n",
      "Epoch 483/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1161.2814 - val_loss: 1167.1412\n",
      "Epoch 484/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.2299 - val_loss: 1123.1771\n",
      "Epoch 485/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1151.2531 - val_loss: 1138.5328\n",
      "Epoch 486/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1141.0558 - val_loss: 1295.1312\n",
      "Epoch 487/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1153.7086 - val_loss: 1123.1897\n",
      "Epoch 488/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1169.6674 - val_loss: 1124.2244\n",
      "Epoch 489/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1135.5544 - val_loss: 1251.9053\n",
      "Epoch 490/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1165.2208 - val_loss: 1203.6388\n",
      "Epoch 491/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1148.5645 - val_loss: 1122.6627\n",
      "Epoch 492/1000\n",
      "75/75 [==============================] - 0s 595us/step - loss: 1161.9493 - val_loss: 1125.2177\n",
      "Epoch 493/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1143.7654 - val_loss: 1124.6136\n",
      "Epoch 494/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1153.9135 - val_loss: 1129.4640\n",
      "Epoch 495/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1146.3971 - val_loss: 1151.1599\n",
      "Epoch 496/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1158.0638 - val_loss: 1138.9678\n",
      "Epoch 497/1000\n",
      "75/75 [==============================] - 0s 825us/step - loss: 1148.0031 - val_loss: 1121.9534\n",
      "Epoch 498/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1148.6727 - val_loss: 1203.5591\n",
      "Epoch 499/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1160.1726 - val_loss: 1180.5193\n",
      "Epoch 500/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1141.7050 - val_loss: 1133.3375\n",
      "Epoch 501/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1161.0206 - val_loss: 1165.4387\n",
      "Epoch 502/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1147.4045 - val_loss: 1120.9407\n",
      "Epoch 503/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.9482 - val_loss: 1142.1353\n",
      "Epoch 504/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1166.8912 - val_loss: 1127.1885\n",
      "Epoch 505/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1152.0015 - val_loss: 1133.3059\n",
      "Epoch 506/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.7391 - val_loss: 1141.5222\n",
      "Epoch 507/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.2341 - val_loss: 1133.1124\n",
      "Epoch 508/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1158.3657 - val_loss: 1127.0980\n",
      "Epoch 509/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1151.6017 - val_loss: 1126.3668\n",
      "Epoch 510/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1155.7129 - val_loss: 1150.9257\n",
      "Epoch 511/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1148.2743 - val_loss: 1159.0897\n",
      "Epoch 512/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1150.2833 - val_loss: 1156.6102\n",
      "Epoch 513/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1152.1698 - val_loss: 1171.5492\n",
      "Epoch 514/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1143.3350 - val_loss: 1121.2192\n",
      "Epoch 515/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.8691 - val_loss: 1143.1011\n",
      "Epoch 516/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.0966 - val_loss: 1122.5916\n",
      "Epoch 517/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1155.4424 - val_loss: 1122.6682\n",
      "Epoch 518/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1160.6963 - val_loss: 1121.9742\n",
      "Epoch 519/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1142.1486 - val_loss: 1120.6833\n",
      "Epoch 520/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1174.8593 - val_loss: 1132.7285\n",
      "Epoch 521/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 649us/step - loss: 1154.0027 - val_loss: 1142.9115\n",
      "Epoch 522/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1158.5143 - val_loss: 1124.0889\n",
      "Epoch 523/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.6761 - val_loss: 1125.7355\n",
      "Epoch 524/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1157.9768 - val_loss: 1121.1204\n",
      "Epoch 525/1000\n",
      "75/75 [==============================] - 0s 852us/step - loss: 1153.1270 - val_loss: 1132.5951\n",
      "Epoch 526/1000\n",
      "75/75 [==============================] - 0s 919us/step - loss: 1154.6121 - val_loss: 1178.3228\n",
      "Epoch 527/1000\n",
      "75/75 [==============================] - 0s 919us/step - loss: 1152.0679 - val_loss: 1148.1316\n",
      "Epoch 528/1000\n",
      "75/75 [==============================] - 0s 797us/step - loss: 1152.2970 - val_loss: 1157.8910\n",
      "Epoch 529/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1146.8616 - val_loss: 1123.9766\n",
      "Epoch 530/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1157.8129 - val_loss: 1165.7102\n",
      "Epoch 531/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1151.2065 - val_loss: 1132.9668\n",
      "Epoch 532/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.8253 - val_loss: 1123.2722\n",
      "Epoch 533/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1157.2852 - val_loss: 1132.0226\n",
      "Epoch 534/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.0579 - val_loss: 1139.2068\n",
      "Epoch 535/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.2150 - val_loss: 1145.5665\n",
      "Epoch 536/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.7018 - val_loss: 1211.4547\n",
      "Epoch 537/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1158.9799 - val_loss: 1131.4778\n",
      "Epoch 538/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1147.0409 - val_loss: 1174.8602\n",
      "Epoch 539/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1146.7888 - val_loss: 1177.7677\n",
      "Epoch 540/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1157.5668 - val_loss: 1143.0305\n",
      "Epoch 541/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1156.4429 - val_loss: 1125.1447\n",
      "Epoch 542/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1150.8617 - val_loss: 1139.7906\n",
      "Epoch 543/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1148.8683 - val_loss: 1200.3950\n",
      "Epoch 544/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.8029 - val_loss: 1149.5403\n",
      "Epoch 545/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.5571 - val_loss: 1128.9324\n",
      "Epoch 546/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1161.1653 - val_loss: 1135.8345\n",
      "Epoch 547/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1161.8954 - val_loss: 1121.2108\n",
      "Epoch 548/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.5967 - val_loss: 1148.2516\n",
      "Epoch 549/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1172.9067 - val_loss: 1176.1646\n",
      "Epoch 550/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.2089 - val_loss: 1120.8994\n",
      "Epoch 551/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.3920 - val_loss: 1123.4891\n",
      "Epoch 552/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1155.9277 - val_loss: 1123.7554\n",
      "Epoch 553/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.3024 - val_loss: 1143.7479\n",
      "Epoch 554/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1166.0530 - val_loss: 1157.2186\n",
      "Epoch 555/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1148.3475 - val_loss: 1134.5967\n",
      "Epoch 556/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1150.2625 - val_loss: 1126.5448\n",
      "Epoch 557/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1144.7401 - val_loss: 1144.6089\n",
      "Epoch 558/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1165.0360 - val_loss: 1156.2574\n",
      "Epoch 559/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1168.8135 - val_loss: 1152.3977\n",
      "Epoch 560/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1165.8181 - val_loss: 1148.9507\n",
      "Epoch 561/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.4775 - val_loss: 1182.6538\n",
      "Epoch 562/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1157.6046 - val_loss: 1123.4369\n",
      "Epoch 563/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1148.5638 - val_loss: 1169.2064\n",
      "Epoch 564/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1156.7733 - val_loss: 1147.0103\n",
      "Epoch 565/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1151.1230 - val_loss: 1120.8374\n",
      "Epoch 566/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1155.8678 - val_loss: 1165.0647\n",
      "Epoch 567/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1163.4764 - val_loss: 1196.5149\n",
      "Epoch 568/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1150.4185 - val_loss: 1127.9565\n",
      "Epoch 569/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.3754 - val_loss: 1153.0627\n",
      "Epoch 570/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.7964 - val_loss: 1151.0315\n",
      "Epoch 571/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.1859 - val_loss: 1163.6531\n",
      "Epoch 572/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1149.5885 - val_loss: 1130.1586\n",
      "Epoch 573/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.7953 - val_loss: 1137.4441\n",
      "Epoch 574/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.2007 - val_loss: 1121.9395\n",
      "Epoch 575/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1156.9410 - val_loss: 1127.5835\n",
      "Epoch 576/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.5499 - val_loss: 1130.4429\n",
      "Epoch 577/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1153.4982 - val_loss: 1141.1450\n",
      "Epoch 578/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1146.7782 - val_loss: 1124.9562\n",
      "Epoch 579/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1137.7975 - val_loss: 1221.3599\n",
      "Epoch 580/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1162.5973 - val_loss: 1142.5410\n",
      "Epoch 581/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.7136 - val_loss: 1150.5930\n",
      "Epoch 582/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1150.1244 - val_loss: 1123.0287\n",
      "Epoch 583/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.7581 - val_loss: 1136.3644\n",
      "Epoch 584/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1161.7401 - val_loss: 1128.5419\n",
      "Epoch 585/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1144.1781 - val_loss: 1126.2788\n",
      "Epoch 586/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1155.2681 - val_loss: 1130.3500\n",
      "Epoch 587/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1178.6296 - val_loss: 1175.1262\n",
      "Epoch 588/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1148.6851 - val_loss: 1154.4684\n",
      "Epoch 589/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1149.1921 - val_loss: 1140.2772\n",
      "Epoch 590/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1149.6545 - val_loss: 1140.1862\n",
      "Epoch 591/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1148.4923 - val_loss: 1133.0570\n",
      "Epoch 592/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.7517 - val_loss: 1145.0173\n",
      "Epoch 593/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1159.5973 - val_loss: 1210.1996\n",
      "Epoch 594/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.4503 - val_loss: 1121.4429\n",
      "Epoch 595/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 622us/step - loss: 1167.0416 - val_loss: 1141.8160\n",
      "Epoch 596/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1155.2333 - val_loss: 1122.9866\n",
      "Epoch 597/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1176.1238 - val_loss: 1152.2384\n",
      "Epoch 598/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1156.0963 - val_loss: 1141.5349\n",
      "Epoch 599/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1158.2992 - val_loss: 1188.5067\n",
      "Epoch 600/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1149.5656 - val_loss: 1155.0055\n",
      "Epoch 601/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.8182 - val_loss: 1185.1982\n",
      "Epoch 602/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.4938 - val_loss: 1245.8918\n",
      "Epoch 603/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1166.1685 - val_loss: 1122.7477\n",
      "Epoch 604/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.9249 - val_loss: 1130.5231\n",
      "Epoch 605/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.0242 - val_loss: 1204.2197\n",
      "Epoch 606/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1161.0088 - val_loss: 1124.8401\n",
      "Epoch 607/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1156.1760 - val_loss: 1152.5918\n",
      "Epoch 608/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1156.1650 - val_loss: 1147.9534\n",
      "Epoch 609/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1144.7279 - val_loss: 1123.8564\n",
      "Epoch 610/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.3024 - val_loss: 1130.4449\n",
      "Epoch 611/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1138.7676 - val_loss: 1128.8650\n",
      "Epoch 612/1000\n",
      "75/75 [==============================] - 0s 595us/step - loss: 1166.0834 - val_loss: 1152.9093\n",
      "Epoch 613/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.6486 - val_loss: 1123.5416\n",
      "Epoch 614/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.9730 - val_loss: 1131.6188\n",
      "Epoch 615/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.7684 - val_loss: 1157.8267\n",
      "Epoch 616/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.5634 - val_loss: 1130.0287\n",
      "Epoch 617/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1164.9749 - val_loss: 1120.8809\n",
      "Epoch 618/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.2980 - val_loss: 1134.5726\n",
      "Epoch 619/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1151.5679 - val_loss: 1141.7753\n",
      "Epoch 620/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.6973 - val_loss: 1163.0469\n",
      "Epoch 621/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1157.7676 - val_loss: 1144.4380\n",
      "Epoch 622/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1144.9042 - val_loss: 1185.7567\n",
      "Epoch 623/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1152.4487 - val_loss: 1144.1511\n",
      "Epoch 624/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1149.0275 - val_loss: 1143.2825\n",
      "Epoch 625/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1153.9857 - val_loss: 1125.6184\n",
      "Epoch 626/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1164.3158 - val_loss: 1172.9760\n",
      "Epoch 627/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.9055 - val_loss: 1137.8942\n",
      "Epoch 628/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1157.9020 - val_loss: 1149.1560\n",
      "Epoch 629/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1160.0782 - val_loss: 1121.4365\n",
      "Epoch 630/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1148.3379 - val_loss: 1121.0216\n",
      "Epoch 631/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1133.7885 - val_loss: 1258.7412\n",
      "Epoch 632/1000\n",
      "75/75 [==============================] - 0s 770us/step - loss: 1152.3704 - val_loss: 1153.6000\n",
      "Epoch 633/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1152.6340 - val_loss: 1126.0480\n",
      "Epoch 634/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1150.2498 - val_loss: 1172.4396\n",
      "Epoch 635/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1156.6705 - val_loss: 1141.4507\n",
      "Epoch 636/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1151.1907 - val_loss: 1145.4707\n",
      "Epoch 637/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1147.7268 - val_loss: 1172.0765\n",
      "Epoch 638/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1173.1748 - val_loss: 1219.8375\n",
      "Epoch 639/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1160.3523 - val_loss: 1126.3452\n",
      "Epoch 640/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1145.7721 - val_loss: 1175.5791\n",
      "Epoch 641/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.3086 - val_loss: 1127.8943\n",
      "Epoch 642/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1150.3245 - val_loss: 1136.8093\n",
      "Epoch 643/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.0850 - val_loss: 1168.1215\n",
      "Epoch 644/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.5730 - val_loss: 1125.0441\n",
      "Epoch 645/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1153.0018 - val_loss: 1124.3087\n",
      "Epoch 646/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1170.3206 - val_loss: 1153.0475\n",
      "Epoch 647/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1155.7825 - val_loss: 1127.0210\n",
      "Epoch 648/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1143.8062 - val_loss: 1168.6974\n",
      "Epoch 649/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1151.5092 - val_loss: 1122.0818\n",
      "Epoch 650/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.9287 - val_loss: 1120.7104\n",
      "Epoch 651/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.7767 - val_loss: 1158.4447\n",
      "Epoch 652/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.3190 - val_loss: 1207.2900\n",
      "Epoch 653/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.4760 - val_loss: 1159.9404\n",
      "Epoch 654/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1156.5199 - val_loss: 1144.0237\n",
      "Epoch 655/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1157.8528 - val_loss: 1144.7046\n",
      "Epoch 656/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.5631 - val_loss: 1173.0059\n",
      "Epoch 657/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1172.5393 - val_loss: 1147.1564\n",
      "Epoch 658/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1151.1643 - val_loss: 1122.1729\n",
      "Epoch 659/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1151.8333 - val_loss: 1127.2407\n",
      "Epoch 660/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1151.5823 - val_loss: 1131.6113\n",
      "Epoch 661/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.8387 - val_loss: 1122.5179\n",
      "Epoch 662/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.6807 - val_loss: 1134.9496\n",
      "Epoch 663/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.5455 - val_loss: 1129.2716\n",
      "Epoch 664/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.2122 - val_loss: 1129.9531\n",
      "Epoch 665/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.8990 - val_loss: 1129.5665\n",
      "Epoch 666/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.0804 - val_loss: 1136.4626\n",
      "Epoch 667/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1148.2164 - val_loss: 1170.8127\n",
      "Epoch 668/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1141.2590 - val_loss: 1121.0020\n",
      "Epoch 669/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 622us/step - loss: 1172.8452 - val_loss: 1133.2405\n",
      "Epoch 670/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.8651 - val_loss: 1153.5989\n",
      "Epoch 671/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1146.1726 - val_loss: 1159.0579\n",
      "Epoch 672/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1153.8334 - val_loss: 1132.4370\n",
      "Epoch 673/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1169.9891 - val_loss: 1129.6169\n",
      "Epoch 674/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1149.3931 - val_loss: 1133.3269\n",
      "Epoch 675/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.1388 - val_loss: 1121.1919\n",
      "Epoch 676/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1152.7850 - val_loss: 1155.7804\n",
      "Epoch 677/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.0128 - val_loss: 1175.1952\n",
      "Epoch 678/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1154.4376 - val_loss: 1158.4824\n",
      "Epoch 679/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.5868 - val_loss: 1162.7543\n",
      "Epoch 680/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1145.5231 - val_loss: 1121.0366\n",
      "Epoch 681/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1158.5597 - val_loss: 1130.1667\n",
      "Epoch 682/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1146.1608 - val_loss: 1121.2280\n",
      "Epoch 683/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1157.7921 - val_loss: 1120.8236\n",
      "Epoch 684/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.3330 - val_loss: 1146.7209\n",
      "Epoch 685/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1160.2836 - val_loss: 1130.3234\n",
      "Epoch 686/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.8914 - val_loss: 1122.8036\n",
      "Epoch 687/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1162.2441 - val_loss: 1165.7162\n",
      "Epoch 688/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1163.3979 - val_loss: 1144.9220\n",
      "Epoch 689/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1151.7794 - val_loss: 1125.1404\n",
      "Epoch 690/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.9878 - val_loss: 1135.9514\n",
      "Epoch 691/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.4480 - val_loss: 1121.1479\n",
      "Epoch 692/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1151.7664 - val_loss: 1137.0620\n",
      "Epoch 693/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1151.6437 - val_loss: 1122.9257\n",
      "Epoch 694/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1159.6208 - val_loss: 1128.2971\n",
      "Epoch 695/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1146.9407 - val_loss: 1170.3131\n",
      "Epoch 696/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.8599 - val_loss: 1120.6802\n",
      "Epoch 697/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1155.6874 - val_loss: 1139.6118\n",
      "Epoch 698/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1142.8290 - val_loss: 1124.2777\n",
      "Epoch 699/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1161.1564 - val_loss: 1156.6044\n",
      "Epoch 700/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1159.2784 - val_loss: 1150.6364\n",
      "Epoch 701/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1143.9734 - val_loss: 1196.5254\n",
      "Epoch 702/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.4056 - val_loss: 1146.8358\n",
      "Epoch 703/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.4340 - val_loss: 1145.6388\n",
      "Epoch 704/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1147.1290 - val_loss: 1270.1893\n",
      "Epoch 705/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.9432 - val_loss: 1154.7021\n",
      "Epoch 706/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1148.4321 - val_loss: 1124.1991\n",
      "Epoch 707/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1142.2800 - val_loss: 1174.2456\n",
      "Epoch 708/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1141.8273 - val_loss: 1200.4635\n",
      "Epoch 709/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1159.1860 - val_loss: 1133.7153\n",
      "Epoch 710/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.4524 - val_loss: 1154.7776\n",
      "Epoch 711/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.9133 - val_loss: 1159.9999\n",
      "Epoch 712/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.3254 - val_loss: 1136.3407\n",
      "Epoch 713/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1156.8966 - val_loss: 1145.4113\n",
      "Epoch 714/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.3615 - val_loss: 1121.6281\n",
      "Epoch 715/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1161.3510 - val_loss: 1124.6779\n",
      "Epoch 716/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1174.0391 - val_loss: 1141.4109\n",
      "Epoch 717/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.7080 - val_loss: 1127.6202\n",
      "Epoch 718/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1160.6254 - val_loss: 1138.7816\n",
      "Epoch 719/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1151.2097 - val_loss: 1137.7139\n",
      "Epoch 720/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1150.9641 - val_loss: 1125.6719\n",
      "Epoch 721/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.3521 - val_loss: 1137.0815\n",
      "Epoch 722/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1165.6935 - val_loss: 1185.9675\n",
      "Epoch 723/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.3651 - val_loss: 1148.0519\n",
      "Epoch 724/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.6631 - val_loss: 1125.4302\n",
      "Epoch 725/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1157.4240 - val_loss: 1125.9780\n",
      "Epoch 726/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.6790 - val_loss: 1137.2412\n",
      "Epoch 727/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.0491 - val_loss: 1122.3989\n",
      "Epoch 728/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1147.5597 - val_loss: 1121.6825\n",
      "Epoch 729/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1181.2284 - val_loss: 1123.5894\n",
      "Epoch 730/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.4929 - val_loss: 1120.8126\n",
      "Epoch 731/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1165.1364 - val_loss: 1123.4155\n",
      "Epoch 732/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1153.8101 - val_loss: 1159.9316\n",
      "Epoch 733/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1155.7590 - val_loss: 1175.4009\n",
      "Epoch 734/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1159.7166 - val_loss: 1127.3376\n",
      "Epoch 735/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.6029 - val_loss: 1166.6942\n",
      "Epoch 736/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1158.6575 - val_loss: 1152.0370\n",
      "Epoch 737/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1141.8402 - val_loss: 1121.7471\n",
      "Epoch 738/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.0220 - val_loss: 1130.8762\n",
      "Epoch 739/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.6266 - val_loss: 1164.1892\n",
      "Epoch 740/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1147.8668 - val_loss: 1127.8302\n",
      "Epoch 741/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1158.2460 - val_loss: 1166.3246\n",
      "Epoch 742/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1147.0610 - val_loss: 1131.7660\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 703us/step - loss: 1144.3468 - val_loss: 1167.7686\n",
      "Epoch 744/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.9531 - val_loss: 1133.0364\n",
      "Epoch 745/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.6479 - val_loss: 1156.8855\n",
      "Epoch 746/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1152.2225 - val_loss: 1124.0483\n",
      "Epoch 747/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.3975 - val_loss: 1130.3282\n",
      "Epoch 748/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1152.3363 - val_loss: 1125.9907\n",
      "Epoch 749/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1153.6417 - val_loss: 1136.3744\n",
      "Epoch 750/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1153.5159 - val_loss: 1142.2164\n",
      "Epoch 751/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.7186 - val_loss: 1177.9423\n",
      "Epoch 752/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1158.0287 - val_loss: 1138.5529\n",
      "Epoch 753/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1148.2799 - val_loss: 1144.7922\n",
      "Epoch 754/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1167.6246 - val_loss: 1197.0016\n",
      "Epoch 755/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1138.6035 - val_loss: 1124.0889\n",
      "Epoch 756/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1151.6591 - val_loss: 1134.2847\n",
      "Epoch 757/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.6952 - val_loss: 1149.0020\n",
      "Epoch 758/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.3610 - val_loss: 1137.2034\n",
      "Epoch 759/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1147.3430 - val_loss: 1141.9498\n",
      "Epoch 760/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1154.1613 - val_loss: 1179.4796\n",
      "Epoch 761/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1155.0836 - val_loss: 1139.2534\n",
      "Epoch 762/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1160.2286 - val_loss: 1145.8865\n",
      "Epoch 763/1000\n",
      "75/75 [==============================] - 0s 608us/step - loss: 1150.0496 - val_loss: 1165.1200\n",
      "Epoch 764/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.0419 - val_loss: 1162.8727\n",
      "Epoch 765/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.5063 - val_loss: 1137.6481\n",
      "Epoch 766/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1161.1750 - val_loss: 1164.6448\n",
      "Epoch 767/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.7943 - val_loss: 1140.3931\n",
      "Epoch 768/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1152.3295 - val_loss: 1186.0964\n",
      "Epoch 769/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.6749 - val_loss: 1122.1178\n",
      "Epoch 770/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1162.8889 - val_loss: 1133.7860\n",
      "Epoch 771/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.2031 - val_loss: 1136.5959\n",
      "Epoch 772/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1151.8103 - val_loss: 1133.1581\n",
      "Epoch 773/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1145.5376 - val_loss: 1130.8713\n",
      "Epoch 774/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1152.0978 - val_loss: 1124.5446\n",
      "Epoch 775/1000\n",
      "75/75 [==============================] - 0s 797us/step - loss: 1144.4552 - val_loss: 1162.3228\n",
      "Epoch 776/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1160.0524 - val_loss: 1163.0775\n",
      "Epoch 777/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1144.6681 - val_loss: 1183.2368\n",
      "Epoch 778/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1158.2921 - val_loss: 1128.7830\n",
      "Epoch 779/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1167.9443 - val_loss: 1166.4617\n",
      "Epoch 780/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1150.5443 - val_loss: 1141.3267\n",
      "Epoch 781/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1167.7289 - val_loss: 1133.0879\n",
      "Epoch 782/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.7190 - val_loss: 1160.1016\n",
      "Epoch 783/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1146.3209 - val_loss: 1155.2090\n",
      "Epoch 784/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1156.3157 - val_loss: 1142.6422\n",
      "Epoch 785/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1155.9800 - val_loss: 1128.7847\n",
      "Epoch 786/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1146.0371 - val_loss: 1135.4677\n",
      "Epoch 787/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.7866 - val_loss: 1131.1302\n",
      "Epoch 788/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.9381 - val_loss: 1141.1737\n",
      "Epoch 789/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1159.1766 - val_loss: 1158.7935\n",
      "Epoch 790/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1145.4663 - val_loss: 1120.7073\n",
      "Epoch 791/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1156.3488 - val_loss: 1133.8258\n",
      "Epoch 792/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1149.1466 - val_loss: 1159.5896\n",
      "Epoch 793/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1154.6040 - val_loss: 1199.5575\n",
      "Epoch 794/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1158.7850 - val_loss: 1166.7899\n",
      "Epoch 795/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.7239 - val_loss: 1186.4082\n",
      "Epoch 796/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1147.7487 - val_loss: 1123.2170\n",
      "Epoch 797/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1157.3204 - val_loss: 1264.4314\n",
      "Epoch 798/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1156.8060 - val_loss: 1129.6052\n",
      "Epoch 799/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1158.1577 - val_loss: 1143.6898\n",
      "Epoch 800/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1149.6093 - val_loss: 1138.3468\n",
      "Epoch 801/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1152.7191 - val_loss: 1127.6202\n",
      "Epoch 802/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1149.3749 - val_loss: 1144.1119\n",
      "Epoch 803/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.8530 - val_loss: 1131.3228\n",
      "Epoch 804/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1158.0424 - val_loss: 1135.8560\n",
      "Epoch 805/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1156.6787 - val_loss: 1139.2350\n",
      "Epoch 806/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1147.6052 - val_loss: 1134.2843\n",
      "Epoch 807/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1156.8101 - val_loss: 1165.3645\n",
      "Epoch 808/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1160.2241 - val_loss: 1155.2087\n",
      "Epoch 809/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1153.8888 - val_loss: 1124.5144\n",
      "Epoch 810/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1151.5228 - val_loss: 1129.3754\n",
      "Epoch 811/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1137.5891 - val_loss: 1198.8020\n",
      "Epoch 812/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1153.4359 - val_loss: 1130.2561\n",
      "Epoch 813/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1153.7861 - val_loss: 1122.1379\n",
      "Epoch 814/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1148.0968 - val_loss: 1121.4604\n",
      "Epoch 815/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1158.3116 - val_loss: 1230.3070\n",
      "Epoch 816/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1142.4014 - val_loss: 1124.5975\n",
      "Epoch 817/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 662us/step - loss: 1162.3341 - val_loss: 1132.6893\n",
      "Epoch 818/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1144.9468 - val_loss: 1165.1272\n",
      "Epoch 819/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1154.1842 - val_loss: 1136.2788\n",
      "Epoch 820/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1151.3820 - val_loss: 1121.1312\n",
      "Epoch 821/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1154.6769 - val_loss: 1144.6729\n",
      "Epoch 822/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.0046 - val_loss: 1122.9678\n",
      "Epoch 823/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1162.3048 - val_loss: 1172.4178\n",
      "Epoch 824/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.4144 - val_loss: 1120.6985\n",
      "Epoch 825/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1152.3284 - val_loss: 1145.5205\n",
      "Epoch 826/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1147.4865 - val_loss: 1121.8351\n",
      "Epoch 827/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1152.6189 - val_loss: 1171.5687\n",
      "Epoch 828/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1153.7302 - val_loss: 1132.7994\n",
      "Epoch 829/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1148.6060 - val_loss: 1142.3864\n",
      "Epoch 830/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1151.9585 - val_loss: 1158.6627\n",
      "Epoch 831/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1137.0322 - val_loss: 1124.1893\n",
      "Epoch 832/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1168.4222 - val_loss: 1123.8312\n",
      "Epoch 833/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.1270 - val_loss: 1126.7020\n",
      "Epoch 834/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.9526 - val_loss: 1138.2401\n",
      "Epoch 835/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.0916 - val_loss: 1163.8800\n",
      "Epoch 836/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.2968 - val_loss: 1152.0452\n",
      "Epoch 837/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.5244 - val_loss: 1123.5162\n",
      "Epoch 838/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1151.2208 - val_loss: 1131.8947\n",
      "Epoch 839/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1161.9048 - val_loss: 1129.1941\n",
      "Epoch 840/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.1475 - val_loss: 1123.0194\n",
      "Epoch 841/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1153.4353 - val_loss: 1122.6379\n",
      "Epoch 842/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1141.9729 - val_loss: 1174.1389\n",
      "Epoch 843/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1162.1000 - val_loss: 1134.3998\n",
      "Epoch 844/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1154.4604 - val_loss: 1139.0381\n",
      "Epoch 845/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1153.5454 - val_loss: 1126.3597\n",
      "Epoch 846/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1163.1747 - val_loss: 1132.7487\n",
      "Epoch 847/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1154.3719 - val_loss: 1149.7220\n",
      "Epoch 848/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1154.4460 - val_loss: 1154.7623\n",
      "Epoch 849/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1161.1870 - val_loss: 1132.8778\n",
      "Epoch 850/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1153.0006 - val_loss: 1134.8562\n",
      "Epoch 851/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.5452 - val_loss: 1141.9685\n",
      "Epoch 852/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1154.3800 - val_loss: 1128.6797\n",
      "Epoch 853/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.1815 - val_loss: 1120.7184\n",
      "Epoch 854/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1154.1768 - val_loss: 1142.3696\n",
      "Epoch 855/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.4097 - val_loss: 1120.7041\n",
      "Epoch 856/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.8496 - val_loss: 1130.0610\n",
      "Epoch 857/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1151.2664 - val_loss: 1164.1887\n",
      "Epoch 858/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.2932 - val_loss: 1134.6740\n",
      "Epoch 859/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.8857 - val_loss: 1172.2654\n",
      "Epoch 860/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1164.4851 - val_loss: 1120.9796\n",
      "Epoch 861/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1152.1927 - val_loss: 1126.8882\n",
      "Epoch 862/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1149.4288 - val_loss: 1140.7113\n",
      "Epoch 863/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1144.5540 - val_loss: 1180.1927\n",
      "Epoch 864/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.8459 - val_loss: 1136.6212\n",
      "Epoch 865/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.1111 - val_loss: 1125.1099\n",
      "Epoch 866/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1157.9486 - val_loss: 1134.6666\n",
      "Epoch 867/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1155.0494 - val_loss: 1121.3906\n",
      "Epoch 868/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1158.9004 - val_loss: 1151.6227\n",
      "Epoch 869/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1157.1511 - val_loss: 1136.1539\n",
      "Epoch 870/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1147.4756 - val_loss: 1164.0732\n",
      "Epoch 871/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.8225 - val_loss: 1147.2869\n",
      "Epoch 872/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1162.4037 - val_loss: 1125.5912\n",
      "Epoch 873/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1153.2556 - val_loss: 1132.3094\n",
      "Epoch 874/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1150.3594 - val_loss: 1137.1686\n",
      "Epoch 875/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1147.0933 - val_loss: 1151.5303\n",
      "Epoch 876/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1151.2645 - val_loss: 1120.8486\n",
      "Epoch 877/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.6439 - val_loss: 1127.1860\n",
      "Epoch 878/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1156.5236 - val_loss: 1158.9269\n",
      "Epoch 879/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1159.5409 - val_loss: 1171.2552\n",
      "Epoch 880/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1152.4613 - val_loss: 1127.5775\n",
      "Epoch 881/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1155.4410 - val_loss: 1121.5468\n",
      "Epoch 882/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1147.4547 - val_loss: 1124.3643\n",
      "Epoch 883/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1164.4060 - val_loss: 1126.6260\n",
      "Epoch 884/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1147.8396 - val_loss: 1124.2106\n",
      "Epoch 885/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.8601 - val_loss: 1125.3085\n",
      "Epoch 886/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1155.1802 - val_loss: 1125.4432\n",
      "Epoch 887/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.7711 - val_loss: 1120.8386\n",
      "Epoch 888/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.7666 - val_loss: 1140.7426\n",
      "Epoch 889/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1146.3734 - val_loss: 1175.0710\n",
      "Epoch 890/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.0573 - val_loss: 1124.0706\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 676us/step - loss: 1142.1353 - val_loss: 1208.6162\n",
      "Epoch 892/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1133.6561 - val_loss: 1121.0458\n",
      "Epoch 893/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.2072 - val_loss: 1167.4614\n",
      "Epoch 894/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1164.1349 - val_loss: 1146.1161\n",
      "Epoch 895/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1153.3043 - val_loss: 1122.5334\n",
      "Epoch 896/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1151.9504 - val_loss: 1121.0575\n",
      "Epoch 897/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1158.2285 - val_loss: 1120.9481\n",
      "Epoch 898/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1149.9999 - val_loss: 1120.7759\n",
      "Epoch 899/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1150.6974 - val_loss: 1149.6860\n",
      "Epoch 900/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1154.1414 - val_loss: 1161.6860\n",
      "Epoch 901/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1147.2378 - val_loss: 1136.7064\n",
      "Epoch 902/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1146.3623 - val_loss: 1132.9994\n",
      "Epoch 903/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1150.4851 - val_loss: 1125.8014\n",
      "Epoch 904/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1141.6572 - val_loss: 1193.5592\n",
      "Epoch 905/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1145.7444 - val_loss: 1127.5045\n",
      "Epoch 906/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1157.1947 - val_loss: 1151.2860\n",
      "Epoch 907/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.5990 - val_loss: 1126.0568\n",
      "Epoch 908/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1146.7415 - val_loss: 1180.5708\n",
      "Epoch 909/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1154.5663 - val_loss: 1148.4196\n",
      "Epoch 910/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1149.1356 - val_loss: 1142.7472\n",
      "Epoch 911/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1148.4948 - val_loss: 1142.1984\n",
      "Epoch 912/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1148.5563 - val_loss: 1135.7629\n",
      "Epoch 913/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1164.8469 - val_loss: 1150.6541\n",
      "Epoch 914/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1155.3000 - val_loss: 1175.9001\n",
      "Epoch 915/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1142.4541 - val_loss: 1122.0291\n",
      "Epoch 916/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.9712 - val_loss: 1121.6659\n",
      "Epoch 917/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1164.2742 - val_loss: 1126.8278\n",
      "Epoch 918/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1147.3452 - val_loss: 1130.1659\n",
      "Epoch 919/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1153.1965 - val_loss: 1124.1826\n",
      "Epoch 920/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1149.2427 - val_loss: 1136.3280\n",
      "Epoch 921/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1145.4839 - val_loss: 1195.6815\n",
      "Epoch 922/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1154.6367 - val_loss: 1150.2476\n",
      "Epoch 923/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1151.7310 - val_loss: 1164.7268\n",
      "Epoch 924/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1149.2373 - val_loss: 1125.8140\n",
      "Epoch 925/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1145.9805 - val_loss: 1125.7483\n",
      "Epoch 926/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1148.3785 - val_loss: 1183.4791\n",
      "Epoch 927/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1147.1384 - val_loss: 1137.4835\n",
      "Epoch 928/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1149.5902 - val_loss: 1148.1917\n",
      "Epoch 929/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1150.0801 - val_loss: 1190.6376\n",
      "Epoch 930/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1140.5164 - val_loss: 1120.8167\n",
      "Epoch 931/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1148.4237 - val_loss: 1128.4811\n",
      "Epoch 932/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1152.5551 - val_loss: 1134.8425\n",
      "Epoch 933/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1163.0083 - val_loss: 1120.9282\n",
      "Epoch 934/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1150.2456 - val_loss: 1141.6359\n",
      "Epoch 935/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1150.4718 - val_loss: 1130.2095\n",
      "Epoch 936/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1147.5911 - val_loss: 1134.8097\n",
      "Epoch 937/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1147.7520 - val_loss: 1162.3812\n",
      "Epoch 938/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1152.1598 - val_loss: 1148.8669\n",
      "Epoch 939/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1151.9288 - val_loss: 1121.7568\n",
      "Epoch 940/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1159.8236 - val_loss: 1138.4954\n",
      "Epoch 941/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1145.7238 - val_loss: 1126.7666\n",
      "Epoch 942/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1160.0839 - val_loss: 1137.6903\n",
      "Epoch 943/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1145.0398 - val_loss: 1120.8772\n",
      "Epoch 944/1000\n",
      "75/75 [==============================] - 0s 770us/step - loss: 1142.1792 - val_loss: 1202.3845\n",
      "Epoch 945/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1156.5433 - val_loss: 1126.6913\n",
      "Epoch 946/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1148.5125 - val_loss: 1178.6442\n",
      "Epoch 947/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1153.1357 - val_loss: 1135.8201\n",
      "Epoch 948/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1154.1267 - val_loss: 1165.4236\n",
      "Epoch 949/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1156.4458 - val_loss: 1211.8848\n",
      "Epoch 950/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1148.0720 - val_loss: 1121.0574\n",
      "Epoch 951/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1151.8656 - val_loss: 1144.0404\n",
      "Epoch 952/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1149.3923 - val_loss: 1122.1853\n",
      "Epoch 953/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1161.1045 - val_loss: 1123.3079\n",
      "Epoch 954/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1144.1256 - val_loss: 1186.7494\n",
      "Epoch 955/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1157.8281 - val_loss: 1196.7019\n",
      "Epoch 956/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.1705 - val_loss: 1159.4542\n",
      "Epoch 957/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.3717 - val_loss: 1130.9236\n",
      "Epoch 958/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1144.3619 - val_loss: 1123.1486\n",
      "Epoch 959/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1157.1078 - val_loss: 1126.0448\n",
      "Epoch 960/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1147.9229 - val_loss: 1127.1143\n",
      "Epoch 961/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1155.9050 - val_loss: 1134.3340\n",
      "Epoch 962/1000\n",
      "75/75 [==============================] - 0s 757us/step - loss: 1152.1246 - val_loss: 1138.4614\n",
      "Epoch 963/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1147.5524 - val_loss: 1192.7589\n",
      "Epoch 964/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1161.7969 - val_loss: 1155.3917\n",
      "Epoch 965/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 649us/step - loss: 1145.0419 - val_loss: 1132.6769\n",
      "Epoch 966/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1150.2488 - val_loss: 1130.9813\n",
      "Epoch 967/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1148.5658 - val_loss: 1153.6237\n",
      "Epoch 968/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.9132 - val_loss: 1182.6205\n",
      "Epoch 969/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1150.4015 - val_loss: 1123.4510\n",
      "Epoch 970/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1148.7180 - val_loss: 1120.7283\n",
      "Epoch 971/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1152.3821 - val_loss: 1121.1276\n",
      "Epoch 972/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1155.4100 - val_loss: 1135.1112\n",
      "Epoch 973/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1151.1487 - val_loss: 1127.3319\n",
      "Epoch 974/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1151.7883 - val_loss: 1129.2286\n",
      "Epoch 975/1000\n",
      "75/75 [==============================] - 0s 716us/step - loss: 1152.3879 - val_loss: 1136.8995\n",
      "Epoch 976/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1153.5497 - val_loss: 1124.4352\n",
      "Epoch 977/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1152.5608 - val_loss: 1125.6874\n",
      "Epoch 978/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1155.6063 - val_loss: 1143.0973\n",
      "Epoch 979/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1151.3474 - val_loss: 1127.1010\n",
      "Epoch 980/1000\n",
      "75/75 [==============================] - 0s 676us/step - loss: 1155.0742 - val_loss: 1152.9204\n",
      "Epoch 981/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1144.6940 - val_loss: 1120.6823\n",
      "Epoch 982/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1150.2343 - val_loss: 1132.8962\n",
      "Epoch 983/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1150.7485 - val_loss: 1145.5023\n",
      "Epoch 984/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1148.3370 - val_loss: 1151.8335\n",
      "Epoch 985/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.8297 - val_loss: 1161.5404\n",
      "Epoch 986/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1162.4871 - val_loss: 1121.0192\n",
      "Epoch 987/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1152.1146 - val_loss: 1120.8502\n",
      "Epoch 988/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1142.3907 - val_loss: 1182.4878\n",
      "Epoch 989/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1137.9453 - val_loss: 1120.7212\n",
      "Epoch 990/1000\n",
      "75/75 [==============================] - 0s 689us/step - loss: 1148.3669 - val_loss: 1159.0895\n",
      "Epoch 991/1000\n",
      "75/75 [==============================] - 0s 730us/step - loss: 1156.1816 - val_loss: 1162.5350\n",
      "Epoch 992/1000\n",
      "75/75 [==============================] - 0s 743us/step - loss: 1144.2341 - val_loss: 1120.8757\n",
      "Epoch 993/1000\n",
      "75/75 [==============================] - 0s 703us/step - loss: 1168.9121 - val_loss: 1120.8110\n",
      "Epoch 994/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1170.6133 - val_loss: 1150.6971\n",
      "Epoch 995/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1156.1750 - val_loss: 1176.8812\n",
      "Epoch 996/1000\n",
      "75/75 [==============================] - 0s 622us/step - loss: 1149.2029 - val_loss: 1172.0750\n",
      "Epoch 997/1000\n",
      "75/75 [==============================] - 0s 649us/step - loss: 1146.7631 - val_loss: 1129.3240\n",
      "Epoch 998/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1152.9585 - val_loss: 1131.5699\n",
      "Epoch 999/1000\n",
      "75/75 [==============================] - 0s 662us/step - loss: 1145.3673 - val_loss: 1120.6805\n",
      "Epoch 1000/1000\n",
      "75/75 [==============================] - 0s 635us/step - loss: 1156.9011 - val_loss: 1135.8385\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain,  ytrain, epochs = 1000, batch_size = 5, validation_split = 0.25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a886ff5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], 'b-', label = 'loss')\n",
    "plt.plot(history.history['val_loss'], 'r-', label = 'val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d85a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 666us/step - loss: 658.8680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "658.8679809570312"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xtest,ytest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c65720a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred= model.predict(xtrain)\n",
    "y_test_pred= model.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc698794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,6],[0,6],color='gray',linestyle='--')\n",
    "plt.scatter(ytrain,y_train_pred, alpha=0.4,color='red')\n",
    "plt.axis([0,6, 0,6])\n",
    "plt.grid(True,alpha=0.5, linestyle='--')\n",
    "plt.xlabel(\"Original\")\n",
    "plt.ylabel(\"train_results\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot([0,6],[0,6],color='gray',linestyle='--')\n",
    "plt.scatter(y_test_pred,ytest, alpha=0.4,color='red')\n",
    "plt.axis([0,6, 0,6])\n",
    "plt.grid(True,alpha=0.5, linestyle='--')\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0adb628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29f0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
